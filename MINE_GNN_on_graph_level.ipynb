{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqZYR93NGMW_"
   },
   "source": [
    "# Package Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSU6Km0aeTjH",
    "outputId": "9b6a0e48-0bbf-4b35-81fb-90f9a498f8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: decorator==5.0.9 in ./miniconda3/lib/python3.8/site-packages (5.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "!pip install -q torch-geometric\n",
    "!pip install decorator==5.0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iiQf0-g_8VtV",
    "outputId": "af209ee6-f2a4-4e41-92cd-df4495ba8a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "# 挂载google drive\n",
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive') \n",
    " \n",
    "nb_path = '/content/notebooks'\n",
    "os.symlink('/content/gdrive/My Drive/Colab Notebooks', nb_path)\n",
    "sys.path.insert(0, nb_path)  # or append(nb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NL4s-L3K-IV2"
   },
   "outputs": [],
   "source": [
    "# 将安装包安装到指定路径（这里安装到Colab Notebooks/python_package目录下）\n",
    "!pip install --target=$nb_path -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "!pip install --target=$nb_path -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "!pip install --target=$nb_path -q torch-geometric \n",
    "!pip install --target=$nb_path decorator==5.0.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ucHRPezrEic",
    "outputId": "9ef02034-5bf5-4602-c16b-4fc2dc8323bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sparse\n",
      "  Using cached sparse-0.14.0-py2.py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from sparse) (0.56.4)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sparse) (1.22.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->sparse) (67.7.2)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->sparse) (0.39.1)\n",
      "Installing collected packages: sparse\n",
      "Successfully installed sparse-0.14.0\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNpx3FGvGT-A"
   },
   "source": [
    "# Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNXtu3Wq_Q7l",
    "outputId": "1023957b-1ce3-48c6-90d9-b387c629007e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "sys.path.insert(0,\"/content/gdrive/My Drive/Colab Notebooks/python_package/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "oN3icR5otZd8",
    "outputId": "f65e0b3f-8ea7-4e4f-c185-9522e4650012"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5d03fa13bb7b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/python_package/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_coo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_coo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compressed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCXS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_dok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDOK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sparse_array\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/python_package/sparse/_coo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_coo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .common import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mconcatenate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/python_package/sparse/_coo/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDArrayOperatorsMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/python_package/numba/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m \u001b[0m_ensure_llvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;31m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/python_package/numba/__init__.py\u001b[0m in \u001b[0;36m_ensure_llvm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m                    \u001b[0;34m\"Please update llvmlite.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                    (_min_llvmlite_version + (llvmlite.__version__,)))\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Not matching?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba requires at least version 0.40.0 of llvmlite.\nInstalled version is 0.39.1.\nPlease update llvmlite.",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj3pVFMFep5A"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display, Javascript\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5I15ZQ6Ber2L",
    "outputId": "48b1876f-2b70-4828-9c83-57035cdabd97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'\n",
    "print(f'Loaded device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyymCSO2ZLVf"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pw0gBOeOCLPh",
    "outputId": "d22431ab-82c7-4893-e332-cab016fd975e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/Mutagenicity.zip\n",
      "Extracting data/mutagen/Mutagenicity/Mutagenicity.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# We will use the Mutagenicity dataset, which is part of the standard datasets in torch geometric.\n",
    "# downloading may take some time\n",
    "dataset = TUDataset(root='data/mutagen', name='Mutagenicity', use_node_attr=True, use_edge_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyRErYqbCS9R"
   },
   "outputs": [],
   "source": [
    "# the below list and dict maps an integer to the corresponiding element string and an element string to a color respectively.\n",
    "# this will be useful for plotting molecules later on\n",
    "\n",
    "element_map = ['C', 'O', 'Cl', 'H', 'N', 'F', 'Br', 'S', 'P', 'I', 'Na', 'K', 'Li', 'Ca']\n",
    "element_color = {\n",
    "    'H': [1.0, 1.0, 1.0],\n",
    " 'Li': [0.8, 0.5019607843137255, 1.0],\n",
    " 'C': [0.5647058823529412, 0.5647058823529412, 0.5647058823529412],\n",
    " 'N': [0.18823529411764706, 0.3137254901960784, 0.9725490196078431],\n",
    " 'O': [1.0, 0.050980392156862744, 0.050980392156862744],\n",
    " 'F': [0.5647058823529412, 0.8784313725490196, 0.3137254901960784],\n",
    " 'Na': [0.6705882352941176, 0.3607843137254902, 0.9490196078431372],\n",
    " 'P': [1.0, 0.5019607843137255, 0.0],\n",
    " 'S': [1.0, 1.0, 0.18823529411764706],\n",
    " 'Cl': [0.12156862745098039, 0.9411764705882353, 0.12156862745098039],\n",
    " 'K': [0.5607843137254902, 0.25098039215686274, 0.8313725490196079],\n",
    " 'Ca': [0.23921568627450981, 1.0, 0.0],\n",
    "'Br': [0.6509803921568628, 0.1607843137254902, 0.1607843137254902],\n",
    " 'I': [0.5803921568627451, 0.0, 0.5803921568627451]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFrRGRTLCZ5w",
    "outputId": "4ba044bf-dedd-4c46-ecd4-9bfcb608e9cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 4337\n",
      "\n",
      "Let's print a few examples' shape:\n",
      "Data(edge_index=[2, 32], x=[16, 14], edge_attr=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[72, 14], edge_attr=[154, 3], y=[1])\n",
      "Data(edge_index=[2, 26], x=[14, 14], edge_attr=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 76], x=[36, 14], edge_attr=[76, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of examples: {len(dataset)}')\n",
    "print('')\n",
    "print(\"Let's print a few examples' shape:\")\n",
    "for i in range(4):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QppEskvDCayg"
   },
   "outputs": [],
   "source": [
    "def draw_molecule(graph, title=''):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    nodes = {}  # create a node dict (idx:element) to create a nx graph\n",
    "    for i in range(graph.x.shape[0]):\n",
    "        element_idx = np.argmax(graph.x[i])\n",
    "        nodes[i] = element_map[element_idx]\n",
    "    edges = []  # create an edge list for the nx graph\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        s, t = graph.edge_index[:, [i]]\n",
    "        s, t = int(s), int(t)\n",
    "        edges.append((s, t))\n",
    "\n",
    "    g = nx.Graph()  # create a graph\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges) \n",
    "    \n",
    "    pos = nx.planar_layout(g)  # the graph has no 'position': generate a node-layout\n",
    "    pos = nx.spring_layout(g, pos=pos)\n",
    "\n",
    "    colors = [element_color[i] for _, i in nodes.items()]  # set the color for each node\n",
    "    nx.draw(g, pos=pos, labels=nodes, node_color=colors, width=1)  # and draw the graph\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.collections[0].set_edgecolor(\"#000000\")  # color the edges\n",
    "    \n",
    "    display(HTML(\"\"\"<style>#output-body {display: flex;align-items: center;justify-content: center;}</style>\"\"\"))  # center the image\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "9u4umQ9-CjsV",
    "outputId": "79141e2b-30a3-4776-efb7-b64abe0ae27a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#output-body {display: flex;align-items: center;justify-content: center;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "draw_molecule(dataset[idx], f'Sample {idx}, Mutagenicity = {bool(dataset[idx].y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WvJ2BlCCmwv"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We simply shuffle and split the dataset to create a train and validation set.\n",
    "'''\n",
    "dataset.shuffle() # first, shuffle our dataset\n",
    "train_idx = round(len(dataset) * 0.8) # 80:20 for the train:validation split\n",
    "dataset_train = dataset[:train_idx]\n",
    "dataset_val = dataset[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfSnIbW8CtTu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "To process the dataset in minibatches, we use a DataLoader object. All we must do\n",
    "is supply the data and set the batch_size, PyTorch Geometric will take care of the rest.\n",
    "Note that the batch_size indicates the number of graphs in a batch, not the number of nodes.\n",
    "'''\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrKBwknSqQBC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "qpW0uzZ5Cx36",
    "outputId": "45e60911-e1e2-4c61-f959-7c97b88bbfd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  3,  3,  3,  3,  4,  4,  4,  4,\n",
      "          5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  9, 10,\n",
      "         11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
      "        [ 1,  2,  3,  9,  0,  2,  4, 10,  0,  1,  0,  5, 11, 12,  1,  6, 13, 14,\n",
      "          3,  7, 15, 16,  4,  8, 17, 18,  5,  8, 19, 20,  6,  7, 21, 22,  0,  1,\n",
      "          3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8]])\n",
      "<class 'torch_geometric.data.data.Data'>\n",
      "[[ 0  0  0  0  1  1  1  1  2  2  3  3  3  3  4  4  4  4  5  5  5  5  6  6\n",
      "   6  6  7  7  7  7  8  8  8  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
      " [ 1  2  3  9  0  2  4 10  0  1  0  5 11 12  1  6 13 14  3  7 15 16  4  8\n",
      "  17 18  5  8 19 20  6  7 21 22  0  1  3  3  4  4  5  5  6  6  7  7  8  8]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e2ef6a7cd816>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (Tensor, Tensor, shape=tuple), but expected one of:\n * (*, torch.device device)\n * (Tensor indices, Tensor values, *, torch.device device)\n * (Tensor indices, Tensor values, tuple of ints size, *, torch.device device)\n * (tuple of ints size, *, torch.device device)\n      didn't match because some of the keywords were incorrect: shape\n"
     ]
    }
   ],
   "source": [
    "# To understand how graphs are batched, print one\n",
    "\n",
    "for data in train_loader:\n",
    "    print(data[0].edge_index)\n",
    "    print(type(data[0]))\n",
    "    print(data[0].edge_index.numpy())\n",
    "    s = torch.sparse.FloatTensor(data[0].edge_index, torch.ones(1, len(data[0].edge_index[0])), shape=(data[0].x.shape[0], data[0].x.shape[0]))\n",
    "    print(s)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjAj7OgqC8kL"
   },
   "outputs": [],
   "source": [
    "num_features = int(dataset_train[0].x.shape[1])\n",
    "num_classes = int(max([d.y for d in dataset_train])+1)\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnOFO3EMwdJB"
   },
   "outputs": [],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98p2tMepdQY1"
   },
   "outputs": [],
   "source": [
    "3470%256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj85cBRFAD5L"
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFXNIR2_ACiK"
   },
   "outputs": [],
   "source": [
    "class Node_to_emb(nn.Module):  # transforms input nodes to an embedding (similar to word embedding in NLP)\n",
    "    #### why would an embedding layer be useful?\n",
    "\n",
    "    def __init__(self, node_feat_dim=14, node_emb_dim=64):\n",
    "        super().__init__()\n",
    "        self.emb_dim = node_emb_dim\n",
    "        self.node_dim = node_feat_dim\n",
    "        self.emb = nn.Linear(self.node_dim, self.emb_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, nodes):\n",
    "        assert nodes.size(-1) == self.node_dim, 'wrong input dimension of node features!'\n",
    "        out = self.emb(nodes)\n",
    "        return out\n",
    "\n",
    "class MpLayer(torch.nn.Module):  # a neural message passing layer\n",
    "    def __init__(self, hidden_dim, activation=nn.ReLU()):\n",
    "        super(MpLayer, self).__init__()\n",
    "        \n",
    "        self.edge_network = nn.Sequential(nn.Linear(2*hidden_dim, hidden_dim),\n",
    "                                          activation,\n",
    "                                          nn.Linear(hidden_dim, hidden_dim),\n",
    "                                          activation\n",
    "                                          )\n",
    "        \n",
    "        self.node_network = nn.Sequential(nn.Linear(2*hidden_dim, hidden_dim),\n",
    "                                          activation,\n",
    "                                          nn.Linear(hidden_dim, hidden_dim),\n",
    "                                          )\n",
    "        \n",
    "    def forward(self, input_to_layer):\n",
    "        node_tensor, edge_idx_tensor = input_to_layer\n",
    "        edge_messages_input = torch.concat([node_tensor[edge_idx_tensor[0,:]], node_tensor[edge_idx_tensor[1,:]]], dim=-1) # shape (num_edges, 2*node_dim + edge_dim)\n",
    "        edge_messages_output = self.edge_network(edge_messages_input) # shape (num_edges, hidden_dim)\n",
    "        \n",
    "        #now aggregate the edge messages for each node the edge points to:\n",
    "        \n",
    "        node_agg_messages = torch.zeros(node_tensor.size(0), node_tensor.size(1)).to(node_tensor.device)\n",
    "        node_agg_messages = node_agg_messages.scatter_add_(\n",
    "            dim=0, index=edge_idx_tensor[1].unsqueeze(-1).expand(-1, node_tensor.size(1)), src=edge_messages_output\n",
    "        )\n",
    "        \n",
    "        \n",
    "        #put the aggregated messages through the node update network:\n",
    "        node_out = self.node_network(torch.cat([node_tensor, node_agg_messages], dim=-1))\n",
    "\n",
    "        return node_out, edge_idx_tensor\n",
    "\n",
    "class MpGNN(torch.nn.Module): # a message passing GNN\n",
    "    def __init__(self, node_feat_dim, hidden_dim, activation=nn.ReLU(), num_classes=2):\n",
    "        super(MpGNN, self).__init__()\n",
    "        \n",
    "        #  Hint: the MpGNN must embed the categorical node features, apply message passing layers,\n",
    "        #        and finally predict the mutagenicity of each graph in the batch.\n",
    "        \n",
    "        self.embedding = Node_to_emb(node_feat_dim, hidden_dim)\n",
    "        self.mp1 = MpLayer(hidden_dim, activation)\n",
    "        self.mp2 = MpLayer(hidden_dim, activation)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        input_model = (x, edge_index)\n",
    "        output_model = self.mp1(input_model)\n",
    "        output_model = self.mp2(output_model)\n",
    "        x, edge_index = output_model\n",
    "        \n",
    "        out = torch.zeros(max(batch)+1, x.size(1)).to(x.device)\n",
    "        idx_aggregate_graph = batch.unsqueeze(-1).expand(-1, x.size(1))\n",
    "    \n",
    "        out.scatter_add_(dim=0, index=idx_aggregate_graph, src=x) # aggregate all node embeddings per graph in the batch\n",
    "        \n",
    "        x = self.fc(out)\n",
    "        return x\n",
    "\n",
    "class Layer_MpGNN(torch.nn.Module): # a message passing GNN\n",
    "    def __init__(self, node_feat_dim, hidden_dim, activation=nn.ReLU(), num_classes=2):\n",
    "        super(Layer_MpGNN, self).__init__()\n",
    "        \n",
    "        #  Hint: the MpGNN must embed the categorical node features, apply message passing layers,\n",
    "        #        and finally predict the mutagenicity of each graph in the batch.\n",
    "        \n",
    "        self.embedding = Node_to_emb(node_feat_dim, hidden_dim)\n",
    "        self.mp1 = MpLayer(hidden_dim, activation)\n",
    "        self.mp2 = MpLayer(hidden_dim, activation)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, batch, training_layer='fc'):\n",
    "        if training_layer == 'embedding':\n",
    "            x = self.embedding(x)\n",
    "            x = (x, edge_index)\n",
    "            \n",
    "        elif training_layer == 'mp1': \n",
    "            x = self.embedding(x)\n",
    "            input_model = (x, edge_index)\n",
    "            x = self.mp1(input_model)\n",
    "            \n",
    "        elif training_layer == 'mp2':\n",
    "            x = self.embedding(x)\n",
    "            input_model = (x, edge_index)\n",
    "            output_model = self.mp1(input_model)\n",
    "            x, edge_index = self.mp2(output_model)\n",
    "\n",
    "            out = torch.zeros(max(batch)+1, x.size(1)).to(x.device)\n",
    "            idx_aggregate_graph = batch.unsqueeze(-1).expand(-1, x.size(1))\n",
    "    \n",
    "            x = out.scatter_add_(dim=0, index=idx_aggregate_graph, src=x) # aggregate all node embeddings per graph in the batch\n",
    "            #print(x, x.shape)\n",
    "        elif training_layer == 'fc':\n",
    "            x = self.embedding(x)\n",
    "\n",
    "            input_model = (x, edge_index)\n",
    "            output_model = self.mp1(input_model)\n",
    "            output_model = self.mp2(output_model)\n",
    "            x, edge_index = output_model\n",
    "        \n",
    "            out = torch.zeros(max(batch)+1, x.size(1)).to(x.device)\n",
    "            idx_aggregate_graph = batch.unsqueeze(-1).expand(-1, x.size(1))\n",
    "    \n",
    "            x = out.scatter_add_(dim=0, index=idx_aggregate_graph, src=x) # aggregate all node embeddings per graph in the batch\n",
    "\n",
    "        \n",
    "            x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4V1vFQOpaLB"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQam1HxIpcP6"
   },
   "outputs": [],
   "source": [
    "def plot_loss(layer1, epoche, loss_type):\n",
    "    \"\"\"\n",
    "    plot the loss change during the training precedure\n",
    "    \"\"\"\n",
    "    plt.title(\"Train \"+ loss_type)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(loss_type)\n",
    "    epoche_range=[i+1 for i in range(epoche)]\n",
    "    plt.plot(epoche_range, layer1)\n",
    "    #plt.plot(epoche_range, layer2)\n",
    "    #plt.plot(epoche_range, fc)\n",
    "    plt.legend([loss_type], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_acc(train, test, epoche):\n",
    "    \"\"\"\n",
    "    plot the loss change during the training precedure\n",
    "    \"\"\"\n",
    "    plt.title(\"Train and validation Accuarcy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    epoche_range=[i+1 for i in range(epoche)]\n",
    "    plt.plot(epoche_range, train)\n",
    "    plt.plot(epoche_range, test)\n",
    "    #plt.plot(epoche_range, fc)\n",
    "    plt.legend(['train accuracy', 'test accuracy'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def eval(model, train_loader = train_loader, isprint=True):\n",
    "    model.eval()  # set the model to evaluation mode (no dropout)\n",
    "    \n",
    "    correct = 0  # keep track of how many we have correct\n",
    "    total = 0  # and how many we handle in total\n",
    "    for data in train_loader:  # loop through the supplied dataset in a batch-wise fashion\n",
    "        data.to(device)  # transfer batch to device\n",
    "        out = model(data.x, data.edge_index, data.batch)  # propagate the data through the model\n",
    "        pred = out.argmax(dim=1)  # as prediction, we take the class with the highest probability\n",
    "        correct += int((pred == data.y).sum())  # add the number of correct predictions\n",
    "        total += len(data.y)  # and add the total number of elements\n",
    "    train_acc = correct / total  # return the accuracy\n",
    "\n",
    "    correct = 0  # keep track of how many we have correct\n",
    "    total = 0  # and how many we handle in total\n",
    "    for data in val_loader:  # loop through the supplied dataset in a batch-wise fashion\n",
    "        data.to(device)  # transfer batch to device\n",
    "        out = model(data.x, data.edge_index, data.batch)  # propagate the data through the model\n",
    "        pred = out.argmax(dim=1)  # as prediction, we take the class with the highest probability\n",
    "        correct += int((pred == data.y).sum())  # add the number of correct predictions\n",
    "        total += len(data.y)  # and add the total number of elements\n",
    "    val_acc = correct / total  # return the accuracy\n",
    "\n",
    "    if isprint:\n",
    "        print('Accuracy of the network on the train: {} %'.format(100 * train_acc))\n",
    "        print('Accuracy of the network on the test: {} %'.format(100 * val_acc))\n",
    "    \n",
    "    return train_acc, val_acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cTAAFRS3tee"
   },
   "source": [
    "# GMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3n7ZmQACGJH"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "EPS = 1e-6\n",
    "\n",
    "class EMALoss(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, running_ema):\n",
    "        ctx.save_for_backward(input, running_ema)\n",
    "        input_log_sum_exp = input.exp().mean().log()\n",
    "\n",
    "        return input_log_sum_exp\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, running_mean = ctx.saved_tensors\n",
    "        grad = grad_output * input.exp().detach() / \\\n",
    "            (running_mean + EPS) / input.shape[0]\n",
    "        return grad, None\n",
    "\n",
    "\n",
    "def ema(mu, alpha, past_ema):\n",
    "    return alpha * mu + (1.0 - alpha) * past_ema\n",
    "\n",
    "\n",
    "def ema_loss(x, running_mean, alpha):\n",
    "    t_exp = torch.exp(torch.logsumexp(x, 0) - math.log(x.shape[0])).detach()\n",
    "    if running_mean == 0:\n",
    "        running_mean = t_exp\n",
    "    else:\n",
    "        running_mean = ema(t_exp, alpha, running_mean.item())\n",
    "    t_log = EMALoss.apply(x, running_mean)\n",
    "\n",
    "    # Recalculate ema\n",
    "\n",
    "    return t_log, running_mean\n",
    "\n",
    "class ConcatLayer(nn.Module):\n",
    "    def __init__(self, dim=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        return torch.cat((x, y), self.dim)\n",
    "\n",
    "\n",
    "class CustomSequential(nn.Sequential):\n",
    "    def forward(self, *input):\n",
    "        for module in self._modules.values():\n",
    "            if isinstance(input, tuple):\n",
    "                input = module(*input)\n",
    "            else:\n",
    "                input = module(input)\n",
    "        return input\n",
    "\n",
    "class T(nn.Module):\n",
    "    def __init__(self, x_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.layers = CustomSequential(ConcatLayer(), nn.Linear(x_dim + z_dim, 400),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(400, 400),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(400, 400),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(400, 1))\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        return self.layers(x, z)\n",
    "\n",
    "class Mine(nn.Module):\n",
    "    def __init__(self, T, loss='mine', alpha=0.01, method=None):\n",
    "        super().__init__()\n",
    "        self.running_mean = 0\n",
    "        self.loss = loss\n",
    "        self.alpha = alpha\n",
    "        self.method = method\n",
    "\n",
    "        if method == 'concat':\n",
    "            if isinstance(T, nn.Sequential):\n",
    "                self.T = CustomSequential(ConcatLayer(), *T)\n",
    "            else:\n",
    "                self.T = CustomSequential(ConcatLayer(), T)\n",
    "        else:\n",
    "            self.T = T\n",
    "\n",
    "    def forward(self, x, z, z_marg=None):\n",
    "        if z_marg is None:\n",
    "            z_marg = z[torch.randperm(x.shape[0])]\n",
    "\n",
    "        t = self.T(x, z).mean()\n",
    "        t_marg = self.T(x, z_marg)\n",
    "\n",
    "        if self.loss in ['mine']:\n",
    "            second_term, self.running_mean = ema_loss(\n",
    "                t_marg, self.running_mean, self.alpha)\n",
    "        elif self.loss in ['fdiv']:\n",
    "            second_term = torch.exp(t_marg - 1).mean()\n",
    "        elif self.loss in ['mine_biased']:\n",
    "            second_term = torch.logsumexp(\n",
    "                t_marg, 0) - math.log(t_marg.shape[0])\n",
    "\n",
    "        return -t + second_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W72qW2mF6b2C"
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "    \n",
    "def negative_sampling(adj_ori, sample_times):\n",
    "    sample_list = []\n",
    "    for j in range(sample_times):\n",
    "        sample_iter = []\n",
    "        i = 0\n",
    "        while True:\n",
    "            randnum = np.random.randint(0,adj_ori.shape[0])\n",
    "            if randnum!=i:\n",
    "                sample_iter.append(randnum)\n",
    "                i = i+1\n",
    "            if len(sample_iter)==adj_ori.shape[0]:\n",
    "                break\n",
    "        sample_list.append(sample_iter)\n",
    "    return sample_list\n",
    "\n",
    "def sp_func(arg):\n",
    "    return torch.log(1+torch.exp(arg))\n",
    "\n",
    "def mi_loss_jsd(pos, neg):\n",
    "    e_pos = torch.mean(sp_func(-pos))\n",
    "    e_neg = torch.mean(torch.mean(sp_func(neg),0))\n",
    "    return e_pos+e_neg\n",
    "\n",
    "def reconstruct_loss(pre, gnd):\n",
    "    nodes_n = gnd.shape[0]\n",
    "    edges_n = np.sum(gnd)/2\n",
    "    weight1 = (nodes_n*nodes_n-edges_n)*1.0/edges_n\n",
    "    weight2 = nodes_n*nodes_n*1.0/(nodes_n*nodes_n-edges_n)\n",
    "    gnd = torch.FloatTensor(gnd).cuda()\n",
    "    temp1 = gnd*torch.log(pre+(1e-10))*(-weight1)\n",
    "    temp2 = (1-gnd)*torch.log(1-pre+(1e-10))\n",
    "    return torch.mean(temp1-temp2)*weight2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VC38aIm83-X4"
   },
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_ft, out_ft, act, bias=True):\n",
    "        super(GCN, self).__init__()\n",
    "        self.fc = nn.Linear(in_ft, out_ft, bias=False)\n",
    "        self.act = nn.PReLU() if act == 'prelu' else act\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(out_ft))\n",
    "            self.bias.data.fill_(0.0)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, seq, adj):\n",
    "        seq_fts = self.fc(seq)\n",
    "        out = torch.unsqueeze(torch.spmm(adj, torch.squeeze(seq_fts, 0)), 0)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        \n",
    "        return self.act(out), seq_fts\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_h1, n_h2):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.f_k = nn.Bilinear(n_h1, n_h2, 1)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, h_c, h_pl, sample_list, s_bias1=None, s_bias2=None):\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, h_c), 2)\n",
    "        sc_1 = self.act(sc_1)\n",
    "        sc_2_list = []\n",
    "        for i in range(len(sample_list)):\n",
    "            h_mi = torch.unsqueeze(h_pl[0][sample_list[i]],0)\n",
    "            sc_2_iter = torch.squeeze(self.f_k(h_mi, h_c), 2)\n",
    "            sc_2_list.append(sc_2_iter)\n",
    "        sc_2_stack = torch.squeeze(torch.stack(sc_2_list,1),0)\n",
    "        sc_2 = self.act(sc_2_stack)\n",
    "\n",
    "        if s_bias1 is not None:\n",
    "            sc_1 += s_bias1\n",
    "        if s_bias2 is not None:\n",
    "            sc_2 += s_bias2\n",
    "\n",
    "        return sc_1, sc_2\n",
    "\n",
    "\n",
    "\n",
    "# Applies mean-pooling on neighbors\n",
    "class AvgNeighbor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgNeighbor, self).__init__()\n",
    "\n",
    "    def forward(self, seq, adj_ori):\n",
    "        adj_ori = sparse_mx_to_torch_sparse_tensor(adj_ori)\n",
    "        if torch.cuda.is_available():\n",
    "            adj_ori = adj_ori.cuda()\n",
    "        return torch.unsqueeze(torch.spmm(adj_ori, torch.squeeze(seq, 0)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8y2ubaC3xkB"
   },
   "outputs": [],
   "source": [
    "class GMI(nn.Module):\n",
    "    def __init__(self, n_in, n_h, activation):\n",
    "        super(GMI, self).__init__()\n",
    "        self.gcn1 = GCN(n_in, n_h, activation)  # if on citeseer and pubmed, the encoder is 1-layer GCN, you need to modify it\n",
    "        self.gcn2 = GCN(n_h, n_h, activation)\n",
    "        self.disc1 = Discriminator(n_in, n_h)\n",
    "        self.disc2 = Discriminator(n_h, n_h)\n",
    "        self.avg_neighbor = AvgNeighbor()\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, seq1, adj_ori, neg_num, adj, samp_bias1, samp_bias2, alpha=0.8, beta=1.0, gamma=1.0):\n",
    "        h_1, h_w = self.gcn1(seq1, adj)\n",
    "        h_2, _ = self.gcn2(h_1, adj)\n",
    "        h_neighbor = self.prelu(self.avg_neighbor(h_w, adj_ori))\n",
    "        \"\"\"FMI (X_i consists of the node i itself and its neighbors)\"\"\"\n",
    "        # I(h_i; x_i)\n",
    "        res_mi_pos, res_mi_neg = self.disc1(h_2, seq1, negative_sampling(adj_ori, neg_num), samp_bias1, samp_bias2)\n",
    "        # I(h_i; x_j) node j is a neighbor\n",
    "        res_local_pos, res_local_neg = self.disc2(h_neighbor, h_2, negative_sampling(adj_ori, neg_num), samp_bias1, samp_bias2)\n",
    "        \"\"\"I(w_ij; a_ij)\"\"\"\n",
    "        adj_rebuilt = self.sigm(torch.mm(torch.squeeze(h_2), torch.t(torch.squeeze(h_2))))\n",
    "        \n",
    "        #loss = args.alpha*process.mi_loss_jsd(res[0], res[1]) + args.beta*process.mi_loss_jsd(res[2], res[3]) + args.gamma*process.reconstruct_loss(res[4], adj_target)\n",
    "        #return res_mi_pos, res_mi_neg, res_local_pos, res_local_neg, adj_rebuilt\n",
    "        return alpha*mi_loss_jsd(res_mi_pos, res_mi_neg) + beta*mi_loss_jsd(res_local_pos, res_local_neg) + gamma*reconstruct_loss(adj_rebuilt, adj_target)\n",
    "\n",
    "    # detach the return variables\n",
    "    def embed(self, seq, adj):\n",
    "        h_1, _ = self.gcn1(seq, adj)\n",
    "        h_2, _ = self.gcn2(h_1, adj)\n",
    "\n",
    "        return h_2.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFxRXUGP9lnO"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-p8QZ31G9lHt"
   },
   "outputs": [],
   "source": [
    "def training_block(num_epochs, model, training_layer, mine, loss_type, optimizer, train_loader, iseval = False):\n",
    "  result_list = []\n",
    "  total_step = len(train_loader)\n",
    "  train_acc_list = []\n",
    "  test_acc_list = []\n",
    "  if loss_type != \"cross entropy\":\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    #print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "    model.train()\n",
    "    sum_MI = 0\n",
    "    for data in train_loader:  # loop through the training set in a batch-wise fashion\n",
    "      data.to(device)  # move the batch to the device (GPU if applicable)\n",
    "      input_feature = data.x\n",
    "      input_edge_index = data.edge_index\n",
    "      y_expanded = torch.zeros(data.y.size(0), 2).to(device)\n",
    "      y_expanded[:, 0] += data.y == 0\n",
    "      y_expanded[:, 1] += data.y == 1 \n",
    "      \n",
    "      # Forward pass\n",
    "      outputs  = model(data.x, data.edge_index, data.batch, training_layer = training_layer)  \n",
    "      if loss_type == '-MI(X;Z)':\n",
    "        output_feature = outputs[0] \n",
    "        output_edge_index = outputs[1]\n",
    "        \n",
    "        loss = mine(input_feature, input_edge_index, M_fake).to(device)\n",
    "      elif loss_type == '-MI(Y;Z)':\n",
    "        labels = labels.view(labels.shape[0], -1).to(device) \n",
    "        loss = mine(labels, outputs).to(device)\n",
    "      elif loss_type == \"cross entropy\":\n",
    "        #labels = labels.view(labels.shape[0], -1).to(device) \n",
    "        loss = mine(outputs, labels).to(device)\n",
    "      \n",
    "      # Backward and optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if loss_type != \"cross entropy\":\n",
    "        scheduler.step()\n",
    "      MI = loss.item()\n",
    "      sum_MI += MI\n",
    "   \n",
    "    avg_MI = sum_MI/total_step\n",
    "    result_list.append(avg_MI)\n",
    "    output = 'Epoch [{}/{}], '+ training_layer+' ' + loss_type +' : {:.12f}' \n",
    "    print (output.format(epoch+1, num_epochs, avg_MI))\n",
    "    if iseval:\n",
    "      if epoch == num_epochs-1:\n",
    "        isprint = True\n",
    "      else:\n",
    "        isprint = False\n",
    "      train_acc, test_acc = eval(model, isprint=isprint)\n",
    "      train_acc_list.append(train_acc)\n",
    "      test_acc_list.append(test_acc)\n",
    "  if len(train_acc_list) == num_epochs: \n",
    "    plot_acc(train_acc_list, test_acc_list, num_epochs)\n",
    "  \n",
    "  if iseval:\n",
    "    return result_list, train_acc_list[-1], test_acc_list[-1]\n",
    "  else:\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYFGOiz-IKvk"
   },
   "source": [
    "# Modular Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0IHV2j5Qebj"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "def Modular_training(model, num_epochs, estimator, loss_list, layer_list, train_dataset):\n",
    "    if len(train_dataset) < 124:\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "    else:\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=124, shuffle=True)\n",
    "    model.train()\n",
    "    for param in model.parameters(): \n",
    "        param.requires_grad = False\n",
    "  \n",
    "    #training embedding\n",
    "    print(\"Training embedding\")\n",
    "    for name, param in model.embedding.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    mine = estimator[0].to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "                                [{\"params\": model.parameters(), \"lr\": 1e-6},\n",
    "                                {\"params\": mine.parameters(), \"lr\": 1e-7}])\n",
    "    loss_type = loss_list[0]\n",
    "    training_layer = layer_list[0]\n",
    "    emb = training_block(num_epochs, model, training_layer, mine, loss_type, optimizer, train_loader)\n",
    "    for name, param in model.embedding.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    #training mp1\n",
    "    print(\"Training mp1\")\n",
    "    for name, param in model.mp1.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    mine = estimator[1].to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "                                [{\"params\": model.parameters(), \"lr\": 1e-6},\n",
    "                                {\"params\": mine.parameters(), \"lr\": 1e-7}])\n",
    "    loss_type = loss_list[1]\n",
    "    training_layer = layer_list[1]\n",
    "    mp1 = training_block(num_epochs, model, training_layer, mine, loss_type, optimizer, train_loader)\n",
    "    for name, param in model.mp1.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    #training mp2\n",
    "    print(\"Training mp2\")\n",
    "    for name, param in model.mp2.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    mine = Mine(estimator[2]).to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "                                [{\"params\": model.parameters(), \"lr\": 1e-6},\n",
    "                                {\"params\": mine.parameters(), \"lr\": 1e-6}])\n",
    "    loss_type = loss_list[2]\n",
    "    training_layer = layer_list[2]\n",
    "    mp2 = training_block(num_epochs, model, training_layer, mine, loss_type, optimizer, train_loader)\n",
    "    for name, param in model.mp2.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    #training fc\n",
    "    print(\"Training fc\")\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "    for name, param in model.fc.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    mine = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_type = loss_list[3]\n",
    "    training_layer = layer_list[3]\n",
    "    fc, train_acc, test_acc = training_block(num_epochs, model, training_layer, mine, loss_type, optimizer, train_loader, iseval=True)\n",
    "    for name, param in model.fc.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    return emb, mp1, mp2, fc, train_acc, test_acc\n",
    "  #return mp1, mp2, fc, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "BtY6DYaz9TK2",
    "outputId": "66a314ae-a28f-4dc7-ebbc-74b1d46e1871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embedding\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bbb10adab3a8>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlayer_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"layer1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"layer2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fc1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fc2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModular_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-a664d0b0e25a>\u001b[0m in \u001b[0;36mModular_training\u001b[0;34m(model, num_epochs, estimator, loss_list, layer_list, train_dataset)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtraining_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-2a79e2945b34>\u001b[0m in \u001b[0;36mtraining_block\u001b[0;34m(num_epochs, model, training_layer, mine, loss_type, optimizer, train_loader, iseval)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msum_MI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model = Layer_MpGNN(14,32).to(device).to(device)\n",
    "T_estimator = [GMI(14, 32, 'prelu'), \n",
    "               GMI(14, 32, 'prelu'),\n",
    "               T(1, 32)]\n",
    "loss_list = ['-MI(X;Z)', '-MI(X;Z)', \"-MI(Y;Z)\", \"cross entropy\"]\n",
    "layer_list = [\"layer1\", \"layer2\", 'fc1', 'fc2']\n",
    "num_epochs = 10\n",
    "layer1, layer2, fc1, fc2, _, _ = Modular_training(model, num_epochs, T_estimator, loss_list, layer_list, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OMYgIjx9Y8z"
   },
   "outputs": [],
   "source": [
    "plot_loss(layer1, num_epochs, loss_list[0])\n",
    "plot_loss(layer2, num_epochs, loss_list[1])\n",
    "plot_loss(fc1, num_epochs, loss_list[2])\n",
    "plot_loss(fc2, num_epochs, loss_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g-a_EgAnR-9"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sy8zC6x4jwVt"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model_save_name = 'DIMonMNIST.pt'\n",
    "path = F\"/content/gdrive/MyDrive/ICML/{model_save_name}\" \n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSGVt05nnT0f"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFp13R2Lj_cn",
    "outputId": "f7ae8ce2-4e85-465e-88e9-02115416e4da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved model\n",
    "model_save_name = 'DIMonMNIST.pt'\n",
    "path = F\"/content/gdrive/MyDrive/ICML/{model_save_name}\"\n",
    "model.load_state_dict(torch.load(path))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TqZYR93NGMW_",
    "T4V1vFQOpaLB",
    "_g-a_EgAnR-9",
    "rSGVt05nnT0f"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
